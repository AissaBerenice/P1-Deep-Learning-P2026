{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# **Project 1 AUTOENCODERS**\n",
    "**DEEP LEARNING**\n"
   ],
   "id": "91993fc4c1839d1"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Dataset",
   "id": "9958b06ebb19c366"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Our dataset comes from 100 images of glasses taken from diverse websites",
   "id": "778579403d337598"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-25T03:34:38.346739Z",
     "start_time": "2026-02-25T03:34:32.360368Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# libraries\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np"
   ],
   "id": "40a23cfb632e2ab0",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-25T03:52:49.239298Z",
     "start_time": "2026-02-25T03:52:41.933541Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "SIZE = (32, 32)\n",
    "images_resized = []\n",
    "bad_files = []\n",
    "\n",
    "for p in image_paths:\n",
    "    try:\n",
    "        with Image.open(p) as img:\n",
    "            img = img.convert(\"RGB\")\n",
    "            img = img.resize(SIZE)\n",
    "            images_resized.append(img)\n",
    "    except Exception as e:\n",
    "        bad_files.append(p.name)\n",
    "\n",
    "print(\"Valid images:\", len(images_resized))\n",
    "print(\"Bad images:\", len(bad_files))\n",
    "print(\"Example bad files:\", bad_files[:15])"
   ],
   "id": "f569ff3df36005cc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid images: 1986\n",
      "Bad images: 14\n",
      "Example bad files: ['0170.jpg', '0278.jpg', '0292.jpg', '0401.jpg', '0670.jpg', '0693.jpg', '0735.jpg', '0170.jpg', '0278.jpg', '0292.jpg', '0401.jpg', '0670.jpg', '0693.jpg', '0735.jpg']\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-25T03:51:38.112481Z",
     "start_time": "2026-02-25T03:51:33.596433Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# getting the images\n",
    "data_dir = Path(\"../data/raw\")\n",
    "image_paths = image_paths = (\n",
    "    list(data_dir.glob(\"*.jpeg\")) +\n",
    "    list(data_dir.glob(\"*.jpg\")) +\n",
    "    list(data_dir.glob(\"*.JPG\")) +\n",
    "    list(data_dir.glob(\"*.JPEG\"))\n",
    ")\n",
    "print(\"Total images:\", len(image_paths))\n",
    "\n",
    "# target size\n",
    "SIZE = (32, 32)\n",
    "\n",
    "# resize all images into a list\n",
    "images_resized = [Image.open(p).resize(SIZE) for p in image_paths]\n",
    "\n",
    "print(\"All images resized to:\", SIZE)\n",
    "\n",
    "# show sample\n",
    "sample = random.sample(images_resized, 15)\n",
    "\n",
    "fig, axes = plt.subplots(5, 3, figsize=(8, 8))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for ax, img in zip(axes, sample):\n",
    "    ax.imshow(img)\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "91a114d70e0b25a5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total images: 2000\n"
     ]
    },
    {
     "ename": "UnidentifiedImageError",
     "evalue": "cannot identify image file 'C:\\\\Users\\\\Aissa\\\\apps\\\\iteso\\\\semestre6\\\\deep-learning\\\\P1-Deep-Learning-P2026\\\\data\\\\raw\\\\0170.jpg'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mUnidentifiedImageError\u001B[0m                    Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[25], line 15\u001B[0m\n\u001B[0;32m     12\u001B[0m SIZE \u001B[38;5;241m=\u001B[39m (\u001B[38;5;241m32\u001B[39m, \u001B[38;5;241m32\u001B[39m)\n\u001B[0;32m     14\u001B[0m \u001B[38;5;66;03m# resize all images into a list\u001B[39;00m\n\u001B[1;32m---> 15\u001B[0m images_resized \u001B[38;5;241m=\u001B[39m \u001B[43m[\u001B[49m\u001B[43mImage\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mopen\u001B[49m\u001B[43m(\u001B[49m\u001B[43mp\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mresize\u001B[49m\u001B[43m(\u001B[49m\u001B[43mSIZE\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mp\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mimage_paths\u001B[49m\u001B[43m]\u001B[49m\n\u001B[0;32m     17\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAll images resized to:\u001B[39m\u001B[38;5;124m\"\u001B[39m, SIZE)\n\u001B[0;32m     19\u001B[0m \u001B[38;5;66;03m# show sample\u001B[39;00m\n",
      "Cell \u001B[1;32mIn[25], line 15\u001B[0m, in \u001B[0;36m<listcomp>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m     12\u001B[0m SIZE \u001B[38;5;241m=\u001B[39m (\u001B[38;5;241m32\u001B[39m, \u001B[38;5;241m32\u001B[39m)\n\u001B[0;32m     14\u001B[0m \u001B[38;5;66;03m# resize all images into a list\u001B[39;00m\n\u001B[1;32m---> 15\u001B[0m images_resized \u001B[38;5;241m=\u001B[39m [\u001B[43mImage\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mopen\u001B[49m\u001B[43m(\u001B[49m\u001B[43mp\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mresize(SIZE) \u001B[38;5;28;01mfor\u001B[39;00m p \u001B[38;5;129;01min\u001B[39;00m image_paths]\n\u001B[0;32m     17\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAll images resized to:\u001B[39m\u001B[38;5;124m\"\u001B[39m, SIZE)\n\u001B[0;32m     19\u001B[0m \u001B[38;5;66;03m# show sample\u001B[39;00m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\PIL\\Image.py:3305\u001B[0m, in \u001B[0;36mopen\u001B[1;34m(fp, mode, formats)\u001B[0m\n\u001B[0;32m   3303\u001B[0m     warnings\u001B[38;5;241m.\u001B[39mwarn(message)\n\u001B[0;32m   3304\u001B[0m msg \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcannot identify image file \u001B[39m\u001B[38;5;132;01m%r\u001B[39;00m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m%\u001B[39m (filename \u001B[38;5;28;01mif\u001B[39;00m filename \u001B[38;5;28;01melse\u001B[39;00m fp)\n\u001B[1;32m-> 3305\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m UnidentifiedImageError(msg)\n",
      "\u001B[1;31mUnidentifiedImageError\u001B[0m: cannot identify image file 'C:\\\\Users\\\\Aissa\\\\apps\\\\iteso\\\\semestre6\\\\deep-learning\\\\P1-Deep-Learning-P2026\\\\data\\\\raw\\\\0170.jpg'"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**Train Test and Validation Split**\n",
    "\n",
    "The resized images are converted to a NumPy array and split into 80% training, 10% validation, and 10% test sets with a fixed random_state for reproducibility. For our experiments, the training set learns the latent representation, the validation set tunes and monitors the model, and the test set evaluates final performance."
   ],
   "id": "1758370888e3c225"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-25T03:48:57.186996Z",
     "start_time": "2026-02-25T03:48:57.010209Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Train test and validation split\n",
    "\n",
    "# Convert the list of images to a NumPy array for splitting\n",
    "images_np = np.array(images_resized)\n",
    "\n",
    "# First split: 80% for training, 20% for (test + validation)\n",
    "X_train, X_test_val = train_test_split(images_np, test_size=0.2, random_state=42)\n",
    "\n",
    "# Second split: 50% of X_test_val for test, 50% for validation (which is 10% each of original data)\n",
    "X_test, X_val = train_test_split(X_test_val, test_size=0.5, random_state=42)\n",
    "\n",
    "print(f\"Training set size: {len(X_train)}\")\n",
    "print(f\"Test set size: {len(X_test)}\")\n",
    "print(f\"Validation set size: {len(X_val)}\")"
   ],
   "id": "8eeb8f56c060cab5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 306\n",
      "Test set size: 38\n",
      "Validation set size: 39\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**Normalization**\n",
    "\n",
    "We are converting the image arrays to `float32` and normalizing them by dividing by 255, since RGB color images have pixel values ranging from 0 to 255. This scales the data to the [0, 1] range, which improves numerical stability and helps the autoencoder train more efficiently."
   ],
   "id": "c95e33b27ef1401c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-25T03:49:00.931418Z",
     "start_time": "2026-02-25T03:49:00.906679Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Normalization\n",
    "X_train = X_train.astype('float32') / 255.0\n",
    "X_test = X_test.astype('float32') / 255.0\n",
    "X_val = X_val.astype('float32') / 255.0\n",
    "\n",
    "print(f\"X_train shape: {X_train.shape}\")  # (80, 256, 256, 3)\n",
    "print(f\"X_test shape: {X_test.shape}\")    # (10, 256, 256, 3)\n",
    "print(f\"X_val shape: {X_test.shape}\")    # (10, 256, 256, 3)\n",
    "print(f\"Min: {X_train.min()}, Max: {X_train.max()}\")"
   ],
   "id": "d67a6f1771e34ceb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (306, 32, 32, 3)\n",
      "X_test shape: (38, 32, 32, 3)\n",
      "X_val shape: (38, 32, 32, 3)\n",
      "Min: 0.0, Max: 1.0\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "6808b85f89ade0e1"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
